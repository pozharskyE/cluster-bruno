{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from preprocess import preprocess_and_return_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = preprocess_and_return_loaders(anime_csv='./data/2020/anime.csv', animelist_csv='./data/2020/animelist.csv')\n",
    "\n",
    "# n_users = len(dataloader.dataset.X[:, 0].unique())\n",
    "n_users = dataloader.dataset.X[:, 0].max()\n",
    "\n",
    "# n_items = len(dataloader.dataset.X[:, 1].unique())\n",
    "n_items = dataloader.dataset.X[:, 1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "\n",
    "        self.users_factors = nn.Embedding(n_users + 1, n_factors, dtype=torch.float32)\n",
    "        self.items_factors = nn.Embedding(n_items + 1, n_factors, dtype=torch.float32)\n",
    "\n",
    "        self.users_factors.weight.data.uniform_(0, 0.1)\n",
    "        self.items_factors.weight.data.uniform_(0, 0.1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        users, items = X[:, 0], X[:, 1]\n",
    "        return (self.users_factors(users) * self.items_factors(items)).sum(1)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixFactorization(n_users, n_items, n_factors=32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fa6026b6db4db5acfa8101e3676fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90510ed6a29147b5be6802960fd07cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 36.891666  [  128/3268479]\n",
      "0\n",
      "loss: 14.410715  [1024128/3268479]\n",
      "8000\n",
      "loss: 11.982721  [2048128/3268479]\n",
      "16000\n",
      "loss: 9.964844  [3072128/3268479]\n",
      "24000\n",
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d562dc306fa4b8e9da8ee551106b7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 8.765333  [  128/3268479]\n",
      "0\n",
      "loss: 9.340118  [1024128/3268479]\n",
      "8000\n",
      "loss: 8.716288  [2048128/3268479]\n",
      "16000\n",
      "loss: 8.376230  [3072128/3268479]\n",
      "24000\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for (batch, (X, y)), it in zip(enumerate(dataloader), tqdm(range(len(dataloader)))):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 8000 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            print(it)\n",
    "\n",
    "for it in tqdm(range(2)):\n",
    "    print(it)\n",
    "    train(dataloader, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.8870e+00,  3.6491e+00,  1.0648e-01,  4.1295e-03,  2.5923e+00,\n",
      "         3.4162e+00,  2.5316e+00,  7.3882e+00,  9.8570e+00,  6.8696e+00,\n",
      "         8.4714e+00,  4.2914e+00,  1.1384e+00,  7.8132e-01,  5.6757e+00,\n",
      "         1.5077e+00,  9.8350e-01,  5.9072e+00,  8.6180e+00,  1.8967e+00,\n",
      "        -3.2273e-04,  1.2517e+00,  7.9205e-02,  6.6435e+00,  8.8029e+00,\n",
      "         2.8759e+00,  5.4153e+00,  4.5798e+00,  5.5915e+00,  7.7585e+00,\n",
      "         7.2467e+00,  3.2597e-01, -2.3073e-03,  4.8519e+00,  4.5392e+00,\n",
      "         4.1101e+00,  7.7587e-01,  7.1731e+00,  5.3604e+00,  7.5192e+00,\n",
      "         7.4152e+00,  8.4449e+00,  7.6797e+00,  6.2861e+00,  4.9725e+00,\n",
      "         4.3446e+00,  7.6379e+00,  2.2655e+00,  3.8958e+00,  4.6676e+00,\n",
      "         4.9968e+00,  7.6176e+00,  5.2193e+00,  3.1771e+00,  9.2011e+00,\n",
      "         9.6923e-02,  4.5034e+00,  7.9497e+00,  5.5428e+00,  7.8051e+00,\n",
      "         6.0845e-01,  8.4267e+00,  2.3527e+00,  9.1270e+00,  7.3240e+00,\n",
      "         4.2550e+00,  7.9985e+00,  7.7096e+00,  7.4690e+00,  9.9491e+00,\n",
      "         2.7905e+00,  5.3434e+00,  3.2600e+00,  5.9408e+00,  4.9314e+00,\n",
      "         2.3096e+00,  9.1185e+00,  2.3211e+00,  2.3912e+00,  4.2827e+00,\n",
      "         4.9844e+00,  2.7611e+00,  5.6733e-01,  5.7048e+00,  5.6080e+00,\n",
      "         2.0951e+00,  8.5405e+00,  7.0875e+00,  5.6446e+00,  3.9057e+00,\n",
      "         4.2991e+00,  6.5489e+00,  5.3813e+00,  7.6138e+00,  4.0412e-01,\n",
      "         6.7823e+00,  1.0371e+01,  5.0300e+00,  3.7633e+00,  2.8528e+00,\n",
      "         2.4842e+00,  6.6278e+00,  2.4721e+00,  2.5383e+00,  2.8398e+00,\n",
      "         5.0573e+00,  6.8508e+00,  3.3945e+00,  3.5538e+00,  6.6856e+00,\n",
      "         2.2168e+00,  5.3615e+00,  7.8238e+00,  6.3869e+00,  5.7091e+00,\n",
      "         6.7959e+00,  6.0891e+00,  1.9200e+00,  1.0721e-01,  2.0855e+00,\n",
      "         7.9516e+00,  5.7631e+00,  1.9984e-01,  7.9176e+00,  6.2304e+00,\n",
      "         7.7286e+00,  8.4723e+00,  4.6561e-02], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for X, y in dataloader:\n",
    "        print(model(X.to(device)))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_user_embeddings = model.users_factors.weight.cpu()\n",
    "trained_item_embeddings = model.items_factors.weight.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_user_embeddings, 'trained_user_embeddings_32.pt')\n",
    "torch.save(trained_item_embeddings, 'trained_item_embeddings_32.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ml-pytorch1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
